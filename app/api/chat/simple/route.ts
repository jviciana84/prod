import { NextRequest, NextResponse } from 'next/server'
import { generateEdelweissResponse, getDatabaseContext } from '@/lib/openai-config'
import { createClient } from '@/utils/supabase/server'

export async function POST(request: NextRequest) {
  try {
    const { message } = await request.json()

    console.log('ğŸ” API Key disponible:', !!process.env.OPENAI_API_KEY)
    console.log('ğŸ“ Mensaje recibido:', message)

    if (!message) {
      return NextResponse.json(
        { error: 'Mensaje es requerido' },
        { status: 400 }
      )
    }

    // Verificar si hay API key de OpenAI
    if (!process.env.OPENAI_API_KEY) {
      console.log('âŒ No hay API key de OpenAI, usando respuesta simulada')
      const response = `Hola! RecibÃ­ tu mensaje: "${message}". Soy Edelweiss, tu asistente de IA. Para usar las funciones completas, necesitas configurar la API key de OpenAI en las variables de entorno.`
      return NextResponse.json({ response })
    }

    console.log('âœ… API key encontrada, llamando a OpenAI...')

    // Obtener contexto de la base de datos
    console.log('ğŸ” Obteniendo contexto de la base de datos...')
    const contextData = await getDatabaseContext('ai-user', message)
    console.log('ğŸ“Š Contexto obtenido:', contextData ? 'SÃ­' : 'No')

    // Obtener historial de conversaciÃ³n
    console.log('ğŸ’¬ Obteniendo historial de conversaciÃ³n...')
    const supabase = createClient()
    const { data: conversationHistory } = await supabase
      .from('ai_conversations')
      .select('message, response')
      .eq('user_id', 'ai-user')
      .eq('session_id', 'ai-session')
      .order('created_at', { ascending: true })
      .limit(10)

    const history = conversationHistory?.map(conv => [
      { role: 'user', content: conv.message },
      { role: 'assistant', content: conv.response }
    ]).flat() || []

    console.log('ğŸ“š Historial obtenido:', history.length, 'mensajes')

    // Generar respuesta del asistente con OpenAI
    console.log('ğŸ¤– Llamando a generateEdelweissResponse...')
    const response = await generateEdelweissResponse(message, history, contextData)

    console.log('âœ… Respuesta de OpenAI recibida:', response.substring(0, 100) + '...')

    // Guardar la conversaciÃ³n en la base de datos
    console.log('ğŸ’¾ Guardando conversaciÃ³n...')
    const { error: insertError } = await supabase
      .from('ai_conversations')
      .insert({
        user_id: 'ai-user',
        session_id: 'ai-session',
        message: message,
        response: response,
        context_data: contextData
      })

    if (insertError) {
      console.error('âŒ Error guardando conversaciÃ³n:', insertError)
    } else {
      console.log('âœ… ConversaciÃ³n guardada correctamente')
    }

    // Actualizar Ãºltima actividad de la sesiÃ³n
    await supabase
      .from('ai_sessions')
      .upsert({
        id: 'ai-session',
        user_id: 'ai-user',
        title: 'Chat con Edelweiss',
        last_message_at: new Date().toISOString()
      })

    return NextResponse.json({ response })

  } catch (error) {
    console.error('Error en API de chat:', error)
    
    // Respuesta de fallback en caso de error
    const fallbackResponse = `Lo siento, hubo un error al procesar tu mensaje. IntÃ©ntalo de nuevo o verifica la configuraciÃ³n de OpenAI.`
    return NextResponse.json({ response: fallbackResponse })
  }
}
