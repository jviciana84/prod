# üîç SCRAPERS BMW PREMIUM SELECTION Y MINI NEXT

## üìã Descripci√≥n

Scrapers para extraer datos de veh√≠culos de ocasi√≥n de las webs p√∫blicas de:
- **BMW Premium Selection** (toda la red BMW Espa√±a)
- **MINI Next** (toda la red MINI Espa√±a)

Estos datos se comparar√°n con nuestro stock interno para generar precios recomendados agresivos.

---

## üì¶ Instalaci√≥n

### 1. Instalar dependencias de Python

```bash
pip install selenium beautifulsoup4 python-dotenv supabase pandas
```

### 2. Instalar ChromeDriver

**Opci√≥n A - Descarga manual:**
1. Ir a https://chromedriver.chromium.org/downloads
2. Descargar versi√≥n compatible con tu Chrome
3. A√±adir al PATH o colocar en carpeta del proyecto

**Opci√≥n B - Instalaci√≥n autom√°tica (recomendado):**
```bash
pip install webdriver-manager
```

Luego usar en el c√≥digo:
```python
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.chrome.service import Service

service = Service(ChromeDriverManager().install())
driver = webdriver.Chrome(service=service)
```

---

## üóÑÔ∏è Configurar Base de Datos

### Crear tablas en Supabase

Ejecutar el script SQL:
```bash
# Conectarse a Supabase y ejecutar
psql -U postgres -d tu_base_datos -f sql/create_bmw_mini_public_scrapers.sql
```

O ejecutar directamente en **Supabase SQL Editor**:
1. Ir a Supabase Dashboard
2. SQL Editor
3. Copiar contenido de `sql/create_bmw_mini_public_scrapers.sql`
4. Ejecutar

Esto crear√°:
- `bmw_premium_selection_public` (veh√≠culos BMW)
- `mini_next_public` (veh√≠culos MINI)
- `price_comparisons` (comparaciones de precios)
- `competitor_price_history` (historial de precios)

---

## üß™ Fase 1: Scrapers de Prueba

### Objetivo
Identificar los selectores CSS/XPath correctos de las webs.

### Ejecutar scraper de prueba BMW

```bash
cd scrapers
python bmw_premium_selection_test.py
```

**¬øQu√© hace?**
1. Accede a BMW Premium Selection
2. Intenta encontrar elementos de veh√≠culos
3. Guarda HTML de la p√°gina para inspecci√≥n manual
4. Muestra posibles selectores encontrados

**Salida:**
- `bmw_premium_selection_page.html` ‚Üí Inspeccionar manualmente
- `bmw_premium_selection_screenshot.png` ‚Üí Captura visual

### Ejecutar scraper de prueba MINI

```bash
cd scrapers
python mini_next_test.py
```

**Salida:**
- `mini_next_page.html` ‚Üí Inspeccionar manualmente
- `mini_next_screenshot.png` ‚Üí Captura visual

---

## üîç Fase 2: Identificar Selectores

### Inspeccionar HTML guardado

1. Abrir archivo HTML generado en navegador
2. Abrir DevTools (F12)
3. Buscar elementos de veh√≠culos

### Selectores a identificar

Para cada veh√≠culo en el listado:
```css
/* Contenedor principal del veh√≠culo */
.vehicle-card, .car-item, article.vehicle

/* Datos b√°sicos */
h2.model-name
span.price
span.mileage
span.year

/* Link a ficha detallada */
a.vehicle-link[href]

/* Imagen principal */
img.vehicle-image[src]
```

Para la ficha detallada:
```css
/* Versi√≥n completa */
h1.vehicle-title

/* Especificaciones t√©cnicas */
.spec-fuel-type
.spec-transmission
.spec-power

/* Extras y equipamiento */
ul.extras-list li
.equipment-item

/* Colores */
.exterior-color
.interior-color

/* Concesionario */
.dealer-name
.dealer-location

/* Galer√≠a de im√°genes */
.gallery-image, .vehicle-photo
```

### Actualizar selectores en c√≥digo

Editar archivos:
- `bmw_premium_selection_test.py` (l√≠nea ~80)
- `mini_next_test.py` (l√≠nea ~80)

Reemplazar selectores de ejemplo con los reales.

---

## üöÄ Fase 3: Scraper Completo

Una vez identificados los selectores, ejecutar scraper completo:

```bash
# BMW Premium Selection (completo)
python bmw_premium_selection_scraper.py

# MINI Next (completo)
python mini_next_scraper.py
```

**Salida:**
- Datos insertados en Supabase
- Log detallado de ejecuci√≥n
- JSON con datos extra√≠dos (backup)

---

## ‚öôÔ∏è Configuraci√≥n Avanzada

### Variables de Entorno (.env)

```env
# Supabase
SUPABASE_URL=https://tu-proyecto.supabase.co
SUPABASE_KEY=tu-anon-key
SUPABASE_SERVICE_ROLE_KEY=tu-service-role-key

# Scraper
HEADLESS_MODE=true
DEBUG_MODE=false
RATE_LIMIT_SECONDS=2
MAX_RETRIES=3

# Notificaciones (opcional)
NOTIFICATION_EMAIL=tu-email@ejemplo.com
```

### Configuraci√≥n de Rate Limiting

Para no sobrecargar las webs:

```python
# Pausas entre requests
DELAY_BETWEEN_PAGES = 2  # segundos
DELAY_BETWEEN_VEHICLES = 1  # segundos
DELAY_BETWEEN_IMAGES = 0.5  # segundos

# Timeouts
PAGE_LOAD_TIMEOUT = 30  # segundos
ELEMENT_WAIT_TIMEOUT = 20  # segundos
```

---

## üîÑ Integraci√≥n en CVO Scraper V1

### A√±adir a `cvo-scraper-v1/main.py`

```python
# Importar scrapers
from scrapers.bmw_premium_selection_scraper import BMWPremiumSelectionScraper
from scrapers.mini_next_scraper import MiniNextScraper

# A√±adir botones en GUI
self.btn_bmw_ps = tk.Button(
    self.frame,
    text="BMW Premium Selection",
    command=self.run_bmw_ps_manual
)

self.btn_mini_next = tk.Button(
    self.frame,
    text="MINI Next",
    command=self.run_mini_next_manual
)

# M√©todo para ejecutar BMW PS
def run_bmw_ps_manual(self):
    if self.bmw_ps_running:
        return
    
    self.bmw_ps_running = True
    self.log("üöó Ejecutando BMW Premium Selection...")
    
    try:
        scraper = BMWPremiumSelectionScraper()
        scraper.init_driver()
        vehicles = scraper.scrape_all()
        scraper.save_to_supabase()
        self.log(f"‚úÖ BMW PS completado: {len(vehicles)} veh√≠culos")
    except Exception as e:
        self.log(f"‚ùå Error en BMW PS: {e}")
    finally:
        self.bmw_ps_running = False
        scraper.close()
```

### Programaci√≥n Autom√°tica

```python
# Ejecutar diariamente a las 02:00 AM
schedule.every().day.at("02:00").do(self.run_bmw_ps_auto)
schedule.every().day.at("02:30").do(self.run_mini_next_auto)
```

---

## üìä Uso de Datos

### Consultar veh√≠culos scrapeados

```sql
-- Ver √∫ltimos veh√≠culos BMW scrapeados
SELECT 
  model, 
  version, 
  price, 
  mileage, 
  dealership_location,
  scraped_at
FROM bmw_premium_selection_public
WHERE is_active = TRUE
ORDER BY scraped_at DESC
LIMIT 20;

-- Ver veh√≠culos MINI scrapeados
SELECT 
  model, 
  version, 
  price, 
  mileage, 
  dealership_location,
  scraped_at
FROM mini_next_public
WHERE is_active = TRUE
ORDER BY scraped_at DESC
LIMIT 20;

-- Ver resumen por modelo
SELECT 
  model,
  COUNT(*) as total,
  AVG(price) as precio_promedio,
  MIN(price) as precio_min,
  MAX(price) as precio_max
FROM bmw_premium_selection_public
WHERE is_active = TRUE
GROUP BY model
ORDER BY total DESC;
```

---

## üêõ Troubleshooting

### Error: ChromeDriver no encontrado

```bash
# Instalar webdriver-manager
pip install webdriver-manager

# O descargar manualmente de
https://chromedriver.chromium.org/downloads
```

### Error: Timeout esperando elementos

**Causa:** Selectores incorrectos o p√°gina tarda en cargar

**Soluci√≥n:**
1. Aumentar `ELEMENT_WAIT_TIMEOUT`
2. Verificar selectores con inspector
3. Ejecutar sin headless para ver qu√© pasa

### Error: Captcha detectado

**Causa:** Medida anti-bot de la web

**Soluciones:**
1. Usar `undetected-chromedriver`:
   ```bash
   pip install undetected-chromedriver
   ```
2. Aumentar delays entre requests
3. Usar proxies rotativos (avanzado)

### Selectores dejan de funcionar

**Causa:** La web cambi√≥ su estructura HTML

**Soluci√≥n:**
1. Ejecutar scraper de prueba
2. Inspeccionar nuevo HTML
3. Actualizar selectores
4. Probar de nuevo

---

## üìÖ Mantenimiento

### Verificaci√≥n Mensual

- [ ] Ejecutar scrapers de prueba
- [ ] Verificar que selectores siguen funcionando
- [ ] Revisar logs de errores
- [ ] Verificar datos en Supabase
- [ ] Actualizar documentaci√≥n si hay cambios

### Monitoreo

```sql
-- Ver √∫ltimos scraping exitosos
SELECT 
  'BMW_PS' as source,
  MAX(scraped_at) as ultimo_scraping,
  COUNT(*) as total_vehiculos
FROM bmw_premium_selection_public
WHERE scraped_at > NOW() - INTERVAL '7 days'
UNION ALL
SELECT 
  'MINI_NEXT' as source,
  MAX(scraped_at) as ultimo_scraping,
  COUNT(*) as total_vehiculos
FROM mini_next_public
WHERE scraped_at > NOW() - INTERVAL '7 days';
```

---

## ‚ö†Ô∏è Consideraciones Legales

### Respetar robots.txt

Verificar qu√© permite cada web:
- https://www.bmw.es/robots.txt
- https://www.mininext.es/robots.txt

### Rate Limiting

**Obligatorio:**
- M√≠nimo 2 segundos entre requests
- No m√°s de 1000 requests por d√≠a
- Horario nocturno preferible (02:00-04:00)

### Uso de Datos

- ‚úÖ Comparaci√≥n interna de precios
- ‚úÖ An√°lisis de mercado
- ‚ùå No redistribuir datos p√∫blicamente
- ‚ùå No usar para spam o publicidad enga√±osa

---

## üìû Soporte

Si tienes problemas:

1. Revisar esta documentaci√≥n
2. Ejecutar scrapers de prueba
3. Revisar logs de error
4. Verificar que ChromeDriver est√° actualizado
5. Consultar documentaci√≥n de Selenium

---

## üîó Enlaces √ötiles

- [Selenium Python Docs](https://selenium-python.readthedocs.io/)
- [BeautifulSoup Docs](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [Supabase Python Client](https://supabase.com/docs/reference/python/introduction)
- [Web Scraping Best Practices](https://www.scrapehero.com/web-scraping-best-practices/)

---

**Versi√≥n:** 1.0  
**√öltima actualizaci√≥n:** 27/10/2025  
**Autor:** Equipo CVO


